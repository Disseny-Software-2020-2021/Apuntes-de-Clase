{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4002d1b",
   "metadata": {},
   "source": [
    "# 3.2 - Pandas Deepdive\n",
    "\n",
    "![pandas_deep](../../images/pandas_deep.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374e168",
   "metadata": {},
   "source": [
    "Antes de empezar con las técnicas de limpieza de datos y visualización vamos a ver como cargar los diferentes tipos de datos con los que podemos trabajar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55e043",
   "metadata": {},
   "source": [
    "#### Tipos de archivos con los que podemos trabajar en pandas\n",
    "\n",
    "    - CSV : 'Comma Separated Values' son archivos de texto plano con los valores separados por comas, si está correctamente codificado pandas interpretará como una tabla y cada una de las comas corresponderá a un dato de una columna, también pueden abrirse desde excel y este los intepretará como una tabla de la misma forma\n",
    "    - xlsx & xls: 'Archivos de excel' importa los datos de un archivo de excel con la salvedad de que únicamente importa los datos de las filas y columnas, pero no las fórmulas que hayamos utilizado para obtenerlos.\n",
    "    - json: JSON son las siglas de \"JavaScript Object Notation\". Un archivo JSON, tiene como extensión los .json, además los datos que contiene son representados en un par llave:valor, igualmente que un objeto JavaScript tradicional. Por simplificar un archivo json podemos interpretarlo como un diccionario de python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61873f9d",
   "metadata": {},
   "source": [
    "**Para poder usar archivos de excel en python deberemos de instalar las siguientes librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e080ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "%pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d9f875",
   "metadata": {},
   "source": [
    "**Importamos las librerías necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920502a",
   "metadata": {},
   "source": [
    "**Cargar un archivo .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('../../../data/Marketing-Customer-Analysis.csv')\n",
    "\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09109234",
   "metadata": {},
   "source": [
    "**Cargar un archivo .xlsx o .xls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('../../../data/retail.xlsx')\n",
    "\n",
    "df_excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55347394",
   "metadata": {},
   "source": [
    "**Cargar un archivo .json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30400526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = pd.read_json('../../../data/companies.json', orient='records', lines=True)\n",
    "\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c924c9",
   "metadata": {},
   "source": [
    "**También podemos cargar datos desde un archivo zip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78767160",
   "metadata": {},
   "outputs": [],
   "source": [
    "zp = zipfile.ZipFile('../../../data/mahindra.zip')\n",
    "\n",
    "df_zip = pd.read_csv(zp.open('test.csv'), nrows=1e5)\n",
    "\n",
    "df_zip.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5c87e",
   "metadata": {},
   "source": [
    "**Guardar datos**\n",
    "\n",
    "    Al igual que podemos importar datos podemos exportar nuestros dataframes a diferentes tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.to_excel('../../../data/Marketing-Customer-Analysis.xlsx', index=False)\n",
    "df_excel.to_json('../../../data/retail.json', orient='table')\n",
    "df_json.to_csv('../../../data/companies.csv', index=False) \n",
    "#el parametro index=False lo usamos para evitar que nos guarde el índice de df como una columna adicional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286117df",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "\n",
    "![cleaning](../../images/cleaning.jpg)\n",
    "\n",
    "\n",
    "$$$$\n",
    "\n",
    "Una vez que hemos conseguido los datos necesarios, es necesario observar su calidad y orden. No se trata de un análisis exploratorio de los datos, sino de ver como de sucios y desordenados están nuestros datos. Cuando los datos tienen problemas de calidad decimos que los datos están sucios. Los problemas de calidad están relacionados con valores nulos, datos inconsistentes, tipo de dato incorrecto y registros duplicados. \n",
    "\n",
    "\n",
    "$$$$\n",
    "![assess](../../images/data_assess.png)\n",
    "$$$$\n",
    "$$$$\n",
    "\n",
    "Por otro lado, el orden de los datos está relacionado con su estructura. Como dice [Hadley Wickham](http://hadley.nz/) en su paper [Tidy Data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html), los datos están ordenados cuando:\n",
    "\n",
    "+ Cada variable forma una columna.\n",
    "+ Cada observación forma una fila.\n",
    "+ Cada tipo de unidad obsservacional forma una tabla.\n",
    "$$$$\n",
    "![clean](../../images/data_clean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489811d4",
   "metadata": {},
   "source": [
    "**Importamos las librerias necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipython\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para quitar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "# muestra todas las columnas del df.head()\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# muestra todas las filas del df\n",
    "#pd.set_option('display.max_rows', None)    \n",
    "\n",
    "# para hacer gráficos\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# para que salga el grafico\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/vehicles_messy.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b04d0b",
   "metadata": {},
   "source": [
    "### Exploración"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48115a1d",
   "metadata": {},
   "source": [
    "Generamos una variable con las dimensiones iniciales de nuestro df para poder comparar con el resultado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9eed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ori = df.shape \n",
    "dim_ori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b833a",
   "metadata": {},
   "source": [
    "**Para ver las columnas de nuestro df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3690dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb6120",
   "metadata": {},
   "source": [
    "**Vamos a ir explorando algunas de las columnas para ver como están nuestros datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f228557",
   "metadata": {},
   "source": [
    "**Podemos ver cuantas columnas tenemos con datos númericos y cuantas categóricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a81a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(exclude='object')\n",
    "\n",
    "num_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b888fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95654d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df.select_dtypes(include='object')\n",
    "\n",
    "cat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116f4ab",
   "metadata": {},
   "source": [
    "**Antes de comenzar nuestro proceso de análisis y limpieza podemos ver una descripción general de nuestro df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eafb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fa14f",
   "metadata": {},
   "source": [
    "**Comenzamos nuestro análisis explorando las columnas con datos nulos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da35add1",
   "metadata": {},
   "source": [
    "Usaremos el método isna() de pandas para comprobar el número de datos nulos que hay en cada columnas y realizamos una suma de los mismos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7accea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663db94",
   "metadata": {},
   "source": [
    "Filtramos nuestro df para ver cuales son las columnas que tienen datos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols[nan_cols>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940362f5",
   "metadata": {},
   "source": [
    "**También podemos hacer el cálculo y mostrarlo como una tasa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c678fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = df.isna().mean()*100\n",
    "\n",
    "nan_cols[nan_cols>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e7cc7",
   "metadata": {},
   "source": [
    "**O mediante un gráfico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c1d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica de nulos en el dataframe\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "sns.heatmap(df.isna(),\n",
    "           yticklabels=False,\n",
    "           cmap='viridis',\n",
    "           cbar = False)\n",
    "\n",
    "plt.show(); # poner ';' para evitar que imprima la dirección de memoria del objeto que estamos pintando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b383ded",
   "metadata": {},
   "source": [
    "Vamos a encapsular en una función el código anterior por si necesitamos el gráfico más adelante y poder reutilzarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_isna(df:pd.DataFrame)->None:\n",
    "    \n",
    "    '''\n",
    "        Función que recibe un dataframe como parámetro y devuelve un heatmap con los datos nulos\n",
    "        de cada una de sus columnas\n",
    "        \n",
    "        Parametros.\n",
    "        -----------\n",
    "        df = Pandas dataframe\n",
    "        \n",
    "        Return.\n",
    "        -----------\n",
    "        \n",
    "        La función muestra por pantalla un heatmap con los datos nulos por cada columna, pero no devuelve nada\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    sns.heatmap(df.isna(),\n",
    "           yticklabels=False,\n",
    "           cmap='viridis',\n",
    "           cbar = False)\n",
    "\n",
    "    plt.show(); # poner ';' para evitar que imprima la dirección de memoria del objeto que estamos pintando\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_isna(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e4871a",
   "metadata": {},
   "source": [
    "Si una columna tiene muchos valores nulos puede ensuciar nuestro análisis e inducirnos a error por lo que si tiene más del 50-60% de sus valores nulos, un opción bastante viable es eliminarla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839cfbca",
   "metadata": {},
   "source": [
    "**Vamos a borrar las columnas con más de 10000 valores nulos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = df.isna().sum()\n",
    "nan_cols[nan_cols>1e4].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6525c88c",
   "metadata": {},
   "source": [
    "**Antes de comenzar la limpieza es bueno realizar una copia de seguridad de nuestros datos originales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22861fd6",
   "metadata": {},
   "source": [
    "Una vez hecha la copia de seguridad comenzamos el proceso de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=nan_cols[nan_cols>1e4].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b38895",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_isna(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee103be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = df.isna().sum()\n",
    "nan_cols[nan_cols>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42daccec",
   "metadata": {},
   "source": [
    "Una vez eliminadas las columnas con mayor número de nulos vamos a proceder a limpiar las columnas que aún tienen datos nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a617c511",
   "metadata": {},
   "source": [
    "### Columna Cylinders & displ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7558ab8",
   "metadata": {},
   "source": [
    "Lo primero que vamos a hacer será localizar los índices de la columna que tienen valores nulos para ver si podemos sacar alguna conclusión de porque nos falta ese dato y si podemos rellenarlo de alguna manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ef5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_index = df.cylinders[df.cylinders.isna()].index\n",
    "\n",
    "bad_index[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ce534",
   "metadata": {},
   "source": [
    "Una vez que tenemos los índices vamos a filtrar nuestro df por esos índices y seleccionaremos una serie de columnas a ver si nos puede ayudar a entender porque nos falta ese dato.\n",
    "\n",
    "En nuestro caso vamos a seleccionar las columnas de 'make', 'model', 'fuelType', 'cylinders', 'displ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e524e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[bad_index][['make', 'model', 'fuelType', 'cylinders', 'displ']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9f127c",
   "metadata": {},
   "source": [
    "En este caso particular parece que la columna fuelType puede ayudarnos a entender el porque la columna cylinders tiene un dato nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d5e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[bad_index][['make', 'model', 'fuelType', 'cylinders', 'displ']].fuelType.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df98b7c",
   "metadata": {},
   "source": [
    "Como podemos observar todos los coches que tenemos aquí tienen motor eléctrico o 'regular', los coches con motor eléctrico no tienen cilindros por ese motivo nos falta ese dato, vamos a ver si podemos entender que marcas tienen el motor 'regular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[bad_index][['make', 'model', 'fuelType', 'cylinders', 'displ']][df.fuelType=='Regular']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a88382",
   "metadata": {},
   "source": [
    "**¿Qué es un motor rotativo?\n",
    "[wikipedia](https://es.wikipedia.org/wiki/Motor_rotativo)\n",
    "\n",
    "Como vemos tanto los motores eléctricos como los rotativos no tienen cilindros, por lo que podemos rellenar nuestros campos con un 0 y de esta manera ya tendríamos esta columna limpia.\n",
    "\n",
    "Para ello utilizaremos el método de pandas fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['cylinders', 'displ']] = df[['cylinders', 'displ']].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[bad_index][['make', 'model', 'fuelType', 'cylinders', 'displ']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15859ba6",
   "metadata": {},
   "source": [
    "### Columna drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d03a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_index = df.drive[df.drive.isna()].index\n",
    "\n",
    "bad_index[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cdc3bc",
   "metadata": {},
   "source": [
    "Vamos a seguir el mismo procedimiento que con las columnas cilynders y displ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[bad_index][['make', 'model', 'fuelType', 'drive']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da0e5d",
   "metadata": {},
   "source": [
    "**Este es el punto donde siempre hay que decidir. ¿Qué nos conviene más, borrar registros o rellenar con un `unknown`?**\n",
    "\n",
    "Para ayudarnos a decidir vamos a ver que tipos drive tenemos en nuestro dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd47d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drive.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6283f7",
   "metadata": {},
   "source": [
    "En este caso y como el volumen de datos incompletos es alto en vez de borrarlos vamos a proceder a rellenar los datos con 'unknown' y de esta manera evitamos perder casi 1200 registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cfa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drive.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = df.isna().sum()\n",
    "\n",
    "nan_cols[nan_cols > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42c745",
   "metadata": {},
   "source": [
    "### Columna trany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2115288",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_index = df.trany[df.trany.isna()].index\n",
    "\n",
    "df.iloc[bad_index][['make', 'model', 'fuelType', 'trany']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.trany.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5399164",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_isna(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446aaf11",
   "metadata": {},
   "source": [
    "**Ahora vamos a proceder a la eliminación de datos duplicados**\n",
    "\n",
    "Para ello tenemos el método de pandas drop_duplicates()\n",
    "\n",
    "Antes de proceder a eliminarlos comprobaremos si realmente hay duplicados o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a308fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates().shape, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f5839",
   "metadata": {},
   "source": [
    "En principio no parece que tengamos datos duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1641d",
   "metadata": {},
   "source": [
    "### Columnas constantes o con baja varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf59c",
   "metadata": {},
   "source": [
    "Primero nos fijaremos en las columnas numéricas, porque hacemos un estudio de esto, una columna constante o con una varianza baja no nos aporta valor a nuestro análisis y puede introducirnos ruido en nuestro posterior modelo, por lo que este tipo de columnas suelen eliminarse de los análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53379b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas ctes\n",
    "\n",
    "cte_cols = []\n",
    "\n",
    "for c in df.select_dtypes(include=np.number): # para columnas de tipo numérico\n",
    "    \n",
    "    if df[c].std()==0: #si la desviación standar de una columna es 0 significa que su valor es cte\n",
    "        cte_cols.append(c)\n",
    "        \n",
    "cte_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db979913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.charge120.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cte_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34843dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cte_cols = []\n",
    "\n",
    "for c in df.select_dtypes(include=np.number): # para columnas de tipo numérico\n",
    "    \n",
    "    if df[c].std()==0:\n",
    "        cte_cols.append(c)\n",
    "        \n",
    "cte_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b211ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cte_str_cols = []\n",
    "\n",
    "for c in df.select_dtypes(include='object'): # para columnas de tipo No numérico\n",
    "    \n",
    "    if len(df[c].unique())==1: #si la columna categorica solo tiene un valor no indica que esta es cte\n",
    "        cte_str_cols.append(c)\n",
    "        \n",
    "cte_str_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a74c5",
   "metadata": {},
   "source": [
    "### Outliers (datos atípicos)\n",
    "\n",
    "Outlier se refiere a esos registros con valores extremos, fuera del rango intercuartil. Dichos valores podrían ser datos verdaderos o fallos de registro. Sea como fuere, se suelen eliminar estos registros porque podrían desplazar la media de una manera ficticia. Esto es, la robustez de los datos. Los datos atípicos 'pesan más' que los datos cercanos a la media. Un solo valor es suficiente para influenciar enormemente la media del conjunto de datos. Esta vez nos fijaremos en los datos por filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e334b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats\n",
    "\n",
    "stats = df.describe().T\n",
    "\n",
    "stats['IQR'] = stats['75%']-stats['25%']\n",
    "\n",
    "stats.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78cbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['youSaveSpend']].boxplot(figsize=(10,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec8a39",
   "metadata": {},
   "source": [
    "Vamos a generar una función que nos calcule el índice IQR de cada una de nuestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d43286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(stats:pd.DataFrame, threshold: float = 1.5)-> pd.DataFrame:\n",
    "    '''\n",
    "        Esta función recibe un dataframe del tipo df.describe().T\n",
    "        \n",
    "        Nos devuelver un dataframe con los outliers\n",
    "        \n",
    "        Params:\n",
    "            stats = pd.DataFrame.describe().T\n",
    "            threshold = float, con el umbral de tukey\n",
    "        \n",
    "        Return:\n",
    "            pd.DataFrame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    stats['IQR'] = stats['75%']-stats['25%']\n",
    "    \n",
    "    outliers = pd.DataFrame(columns=stats.index)\n",
    "    \n",
    "    for c in stats.index:\n",
    "        iqr = stats.at[c, 'IQR']\n",
    "        \n",
    "        cut_off = threshold * iqr \n",
    "        \n",
    "        lower = stats.at[c, '25%'] - cut_off\n",
    "        upper = stats.at[c, '75%'] + cut_off\n",
    "        \n",
    "        res = df[(df[c] < lower) | (df[c] > upper)].copy()\n",
    "        \n",
    "        res['outliers'] = c\n",
    "        \n",
    "        outliers = outliers.append(res, sort=True)\n",
    "    \n",
    "    print(outliers['outliers'].value_counts())\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = get_outliers(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9025a78b",
   "metadata": {},
   "source": [
    "Ahora vamos extraer los índices de este df en una lista para filtrar nuestro df y de esta manera quitar los datos atípicos de nuestro df.\n",
    "\n",
    "**¡¡¡OJO!!!!** Solo se quitan outliers una sola vez, ya que siempre habrá datos que superen los límites de \"normalidad\" y corremos el riesgo de quedarnos sin datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d79dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_index = [i for i in df.index if i not in outliers.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0171dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[clean_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['youSaveSpend']].boxplot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40681c82",
   "metadata": {},
   "source": [
    "### Colinealidad\n",
    "\n",
    "    A grosso modo podemos decir que existe colinealidad entre dos columnas cuando ambas nos están aportando la misma información, bien porque sean la misma o porque una es combinación lineal de la otra\n",
    "    \n",
    "    Para estudiar la colinealidad lo haremos a través de la matriz de correlación, si en esta encontramos valores nulos signifacará que la varianza entre ambas columnas es 0.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dee8be",
   "metadata": {},
   "source": [
    "\n",
    "$$\\rho(X,Y)=\\frac{\\sigma{X,Y}}{\\sigma{X}\\sigma{Y}} =\\frac{Cov(X,Y)}{\\sqrt{ Var{(X)} Var{(Y)}}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49455f",
   "metadata": {},
   "source": [
    "$$\\rho{(X,Y)}$$ es la correlación de pearson\n",
    "\n",
    "$$\\sigma{(X,Y)}$$ es la covarianza de (X,Y)\n",
    "\n",
    "$$\\sigma{(X)}$$ es la desviación estándar de (X)\n",
    "\n",
    "$$\\sigma{(Y)}$$ es la desviación estándar de (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964d2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cda4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas ctes\n",
    "\n",
    "cte_cols = []\n",
    "\n",
    "for c in df.select_dtypes(include=np.number):\n",
    "    \n",
    "    if df[c].std()==0:\n",
    "        cte_cols.append(c)\n",
    "\n",
    "cte_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb3df82",
   "metadata": {},
   "source": [
    "Este resultado se debe al que al eliminar los outliers la desviación estándar de nuestras columnas ha variado con el resultado mostrado arriba, haciendo que ahora estas columnas tengan una varianza de 0 y por lo tanto podemos tratarlas como columnas constantes.\n",
    "Como hemos dicho antes todas estas columnas no nos aportan valor a nuestro análisis y vamos a eliminarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=cte_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8031d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ae0b1",
   "metadata": {},
   "source": [
    "Vemos que al volver a calcular la matriz de correlación nos aparece columna con Nulos que no estaba en la lista anterior, siguiendo el mismo procediento vamos a eliminarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('phevBlended', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ee613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterio de colianelidad\n",
    "\n",
    "colineales = []\n",
    "\n",
    "for c in df._get_numeric_data(): # para cada columna numerica ...\n",
    "    \n",
    "    for i in range(len(df.corr())): # vamos a recorrer la matriz de correlación ..\n",
    "        \n",
    "        if abs(df.corr()[c][i])>0.9 and abs(df.corr()[c][i])<1: \n",
    "            # el umbral es arbitrario, abs es el valor absoluto del dato\n",
    "            #print('columna que estay explorando ', c)\n",
    "            \n",
    "            #print('valor de la matriz de correlación ', df.corr()[c][i] )\n",
    "            colineales.append(c)\n",
    "\n",
    "colineales = list(set(colineales))\n",
    "\n",
    "len(colineales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colineales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f4125",
   "metadata": {},
   "source": [
    "Al igual que pasa con las columnas constantes, la colinealidad nos dice que estas columnas aportan el mismo dato respecto a la que la hemos comparado, por lo que podemos eliminar dicha columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=colineales, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb467cbf",
   "metadata": {},
   "source": [
    "### Normalización columna trany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.trany.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452d0dc",
   "metadata": {},
   "source": [
    "Vamos utilizar el método apply de pandas para aplicar una función a la columna trany en la que nos cambie el valor por 'MANUAL' si el dato que recibe la función contiene la substring 'Man', 'AUTO' si el dato que recibe contiene la substring 'Au' o que deje el dato tal cual está si no contiene ninguno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b746e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.trany = df.trany.apply(lambda x: 'MANUAL' if 'Man' in x else ('AUTO' if 'Au' in x else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.trany.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a564924",
   "metadata": {},
   "source": [
    "Como solo tenemos un dato 'unknown' vamos a eliminarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.trany=='unknown'].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176b9f9",
   "metadata": {},
   "source": [
    "## Dataframe Final\n",
    "\n",
    "    Para finalizar vamos a resetear los índices de nuestro df para que todo quede en orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e693c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92bf57",
   "metadata": {},
   "source": [
    "Nuestro dataset ocupa ahora 11,3 MB, pero vamos a ver si podemos cambiar el tipo de dato para ocupe lo menos posible y de esta forma podamos bajar el coste computacional si quisieramos usarlo para entrenar modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12dbf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tqdm(['object', 'integer', 'float']):\n",
    "    for c in tqdm(df.select_dtypes(d).columns):\n",
    "        if d == 'object':\n",
    "            df[c]=df[c].astype('category')\n",
    "        elif d == 'integer':\n",
    "            df[c] = pd.to_numeric(df[c], downcast='integer')\n",
    "        elif d == 'float':\n",
    "            df[c] = pd.to_numeric(df[c], downcast='float')\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e62731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0f3a6",
   "metadata": {},
   "source": [
    "Con esto hemos pasado de 11,3MB a 603,2 KB lo que haría que si usaramos este dataset para entrenar un modelo trabajar de forma mas eficiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb445dca",
   "metadata": {},
   "source": [
    "### Para finalizar guardamos nuestro df limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../../data/Vehicles_messy_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
