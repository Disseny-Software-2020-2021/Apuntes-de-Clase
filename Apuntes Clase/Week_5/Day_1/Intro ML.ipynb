{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f714ab-4c10-4b2e-b69a-656c8d9eeaa9",
   "metadata": {},
   "source": [
    "# 5.1 - Intro Machine Learning - Aprendizaje Supervisado - Regresion\n",
    "\n",
    "![venn_ml](../../images/venn_ml.png)\n",
    "\n",
    "![ext_sklearn](../../images/ext_sklearn.jpeg)\n",
    "\n",
    "![sklearn](../../images/sklearn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce817f03-6864-42f9-8943-79f14db5bb11",
   "metadata": {},
   "source": [
    "### WorkFlow\n",
    "\n",
    "\n",
    "1. [Obtener datos](#1.-Obtener-Datos)\n",
    "2. [Definir objetivo](#2.-Definir-Objetivo)\n",
    "3. [Limpieza de datos (unidades, outliers, one-hot, etc..)(**)](#3.-Limpieza-de-Datos)\n",
    "4. [Definir modelo (regresión, clasificación, ...)](#4.-Modelo)\n",
    "5. [Entrenar (hiperparámetros, validación, ...) (**)](#5.-Entrenamiento)\n",
    "6. [Predecir (testear)](#6.-Predicción)\n",
    "7. [Evaluación](#7.-Evaluación)\n",
    "8. [Si hay mucho error volver a (**)](#WorkFlow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5796fb4-eb3e-4076-b2ac-2429e3b063f5",
   "metadata": {},
   "source": [
    "Lo primero como siempre importamos nuestras librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e1e2a-c3dd-40c4-ae77-100995931b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dda82-b4ff-4b18-8ac9-e9ccd7ed58fd",
   "metadata": {},
   "source": [
    "Para este ejemplo vamos a trabajar con un dataset sobre diamantes, la idea es predecir el precio de un diamante en base a sus características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f111c79-b3b5-43cc-ba03-fb8c389d219d",
   "metadata": {},
   "source": [
    "### 1. Obtener Datos\n",
    "\n",
    "**explicacion:**\n",
    "    \n",
    "+ carat:\tpeso del diamante (quilates)\n",
    "\n",
    "+ cut:\tcalidad del corte (Fair, Ideal, Good, Very Good, Premium)\n",
    "\n",
    "+ color: color (D (mejor) a J (peor))\n",
    "\n",
    "+ clarity: claridad (I1 (peor), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (mejor)) \n",
    "\n",
    "+ table: ancho del corte superior del diamante\n",
    "\n",
    "+ x: largo en mm\n",
    "\n",
    "+ y: ancho en mm\n",
    "\n",
    "+ z: alto en mm\n",
    "\n",
    "+ depth:\t2*z/(x+y)\n",
    "\n",
    "+ price:\tprecio en dolares USA\n",
    "\n",
    "\n",
    "![dia](../../images/dia.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e71d6-8fed-4f36-a62d-ef9cae651f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../../data/diamonds.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32832fbc-926b-4e66-be47-bc6f8f998141",
   "metadata": {},
   "source": [
    "Vamos ver como es la calidad de nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e31a54-d152-4dee-a9d4-259f29c1f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dda68f5-7dd2-425e-af26-735b1a41d008",
   "metadata": {},
   "source": [
    "### 2. Definir nuestro objetivo\n",
    "\n",
    "Como hemos dicho al principio nuestro objetivo es tratar de predecir el precio de un diamante en base a sus caracteristicas, carat, corte, color, clarity, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b0c63-02f5-42e1-b020-e38b15bde982",
   "metadata": {},
   "source": [
    "### 3. Limpieza de Datos\n",
    "\n",
    "El proceso de limpieza es el habitual:\n",
    "\n",
    "+ Valores nulos\n",
    "+ Datos inconsistentes \n",
    "+ Datos duplicados...\n",
    "\n",
    "Todo esto implica realizar también un **EDA**. Además de eso, es necesario arreglar los datos, proceso llamado `data wrangling`. Este proceso consiste en preparar los datos de manera adecuada para que el modelo de machine learning \"entienda\" los datos de manera óptima. Por ejemplo, los datos de corte, color y claridad son datos categóricos que están en formato string, habrá que cambiar estos datos para alimentar al modelo, las máquinas solo entienden de números 🤣.\n",
    "\n",
    "Este proceso no es solo necesario sino fundamental. **Todo está en los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ee76b-c513-4d86-9939-28d82c6963dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3a278-b5b7-4964-88dd-1b6cf4292d45",
   "metadata": {},
   "source": [
    "En principio nuestros datos parece que no contienen datos nulos, por lo que podemos avanzar al siguiente paso, en el caso de que si hubiera contenido datos nulos, deberíamos de haber explorado las columnas que contenían estos datos y decir como tratar esos valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0c3eb-6219-4ffb-b78c-f1e7fed79f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f5111-44fa-4bef-a72a-43fb857f0d14",
   "metadata": {},
   "source": [
    "El parámetro include 'all' del método describe nos muestra todos los datos estadísticos de nuestras columnas, incluyendo las categóricas que en su caso nos devuelve parámetros tales como el conteo, el número de valores únicos por categoría, la moda y su frecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7766109-f636-47bc-9a1c-d4480c293005",
   "metadata": {},
   "source": [
    "Ahora vamos a imprimir nuestra matriz de correlación para comprobar si hay colinealidad entre las variables de nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6ef1a-8068-4b1e-8bca-25d450b253c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.set(style='white')\n",
    "\n",
    "mask=np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "\n",
    "cmap=sns.diverging_palette(0, 10, as_cmap=True)\n",
    "\n",
    "\n",
    "sns.heatmap(df.corr(),\n",
    "           mask=mask,\n",
    "          cmap=cmap,\n",
    "          center=0,\n",
    "          square=True,\n",
    "          annot=True,\n",
    "          linewidths=0.5,\n",
    "          cbar_kws={'shrink': 0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fa697-411a-4f3a-81c4-baf75173967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df, figsize=(15, 10), alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b8154-86d6-413c-89b6-86e1bd676f1a",
   "metadata": {},
   "source": [
    "Vamos a ver alguna de las columnas en particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ae6fc-dbf2-42a6-82e7-18da66fd02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.scatter(df.price, df.carat)\n",
    "\n",
    "plt.ylabel('carat')\n",
    "plt.xlabel('price');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5ec56-90bf-40b0-a5a6-5cfa014157ae",
   "metadata": {},
   "source": [
    "Al comparar precio y quilates vemos que hay cierta relación lineal, a más quilates mayor precio, aunque también podemos observar varios grupos en los que seguramente entre otro tipo de caracteristica que ayude a predecir su precio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579a3d0-b255-43ca-979c-c313022e374f",
   "metadata": {},
   "source": [
    "Vamos a tratar de transformar esta variable para ver si podemos eliminar esa dependecia de otras caracteristicas para tratar de encontrar si hay o no relación lineal entre ambas, para ello podemos usar la transformación de box-cot.\n",
    "Las transformaciones de Box y Cox son una familia de transformaciones potenciales usadas en estadística para corregir sesgos en la distribución de errores, para corregir varianzas desiguales (para diferentes valores de la variable predictora) y principalmente para corregir la no linealidad en la relación (mejorar correlación entre las variables). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7f6e0-f9ed-432d-a615-f8b684a79884",
   "metadata": {},
   "source": [
    "[Documentación](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html) Libería Scipy\n",
    "\n",
    "[Wikipedia](https://es.wikipedia.org/wiki/Transformaci%C3%B3n_Box-Cox) Transformación de Box y Cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33062167-7a73-4e46-a6d3-5cc5a642160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f371d5-6abd-4a99-b249-6c8ab54f2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "carat_boxcox=boxcox(df.carat, lmbda=2.618033) #este lambda es un valor aleatorio la idea sería ir haciendo experimentos\n",
    "\n",
    "plt.scatter(df.price, carat_boxcox)\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('carat_boxcox');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c006c57-3b88-4ce6-99ef-2189bf8fd0e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reflexión : ¿Cómo podemos asegurarnos de que de verdad son diamantes?\n",
    "\n",
    "1 carat es igual a 200mg de diamante.\n",
    "\n",
    "Densidad del diamante es 2,26 gm/cm3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db556ef-5da1-4f6d-a833-6fc17eb63391",
   "metadata": {},
   "source": [
    "Con estos datos vamos a tratar de ver si todos los elementos que tenemos en nuestro dataset son diamantes o no, para ello vamos a realizar una copia de nuestros datos y vamos a añadirle una serie de nuevas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf3c3a-f8ad-4d51-833d-8e647fdec758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "\n",
    "df2['gr'] = 0.2 * df2.carat # obtenemos el peso del diamante a partir de los quilates\n",
    "\n",
    "df2['vol']=df2.x * df2.y * df2.z / 2.5 / 1000 # obtenemos el volumen aproximando\n",
    "\n",
    "df2['density']= df2.gr / df2.vol # obtenemos la densidad aproximada a partir de su peso y volumen\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf2e2c-c48b-497e-85ea-9e4bb85e3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b0263-dde4-4f00-ac6d-c859e67898d6",
   "metadata": {},
   "source": [
    "Vemos que la densidad en algunos casos se nos sale de los calculos normales, esto nos está indicando que algunos de los datos que tenemos no son diamantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679905c8-6892-4a23-a562-f5cc9a6f85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.density > 3.9].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f4001-eb91-4f7f-9646-4917e8e505d0",
   "metadata": {},
   "source": [
    "Nos basamos en la densidad del diamante que es 3,5, pero dado que nuestro calculo del volumen ha sido una aproximación vamos a dar un margen, con estos datos vemos que hay 27 registros que están por encima de 3.9 y por debajo de 2.9, posiblemente sean lo que se denominan diamantes sintéticos, que se usan en la industria de semiconductores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430f6410-372c-4f2d-b132-f05807a2bf04",
   "metadata": {},
   "source": [
    "Por ello si queremos realmente predecir el precio de un diamante como tal este tipo de datos debemos excluirlos porque pueden introducir sesgos en nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f6260-1ae5-4385-97f7-21ba8ea3442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.density < 2.9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f58649d-be3a-404e-9cfe-95027e4d7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonts = df2[(df2.density>2.9)&(df2.density<3.9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b19b8-3c70-4507-a86c-2d25711da754",
   "metadata": {},
   "source": [
    "Una vez tenemos las transformaciones que necesitabamos vamos a pasar a la preparación de los datos para entrenar nuestro modelo, cabe decir que si queremos realizar nuestro experimentos de forma óptima deberíamos de hacer este proceso por separado y de forma independiente para cada uno de nuestros modelos ya que dependiendo del algoritmo que vayamos a entrenar una transformación de datos puede mejorar o empeorar su desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbb0e1-ecf5-4a6d-8adf-102a23cbc647",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer es dividir nuestro set de datos en datos de entrenamiento y datos de test, esto lo hacemos para poder probar el desempeño de nuestro modelo con datos que no conoce, y así comprobar la eficacia del mismo cuando recibamos datos nuevos y queramos predecir el precio de un nuevo diamante, con la salvedad de que en nuestros datos de test si tenemos precio por lo que con el podemos evaluar como se está desviando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48cf4ba-df55-4169-9a43-d5fba3bd8187",
   "metadata": {},
   "source": [
    "## Separación de datos.\n",
    "\n",
    "![X_y_tts](../../images/X_y_tts.png)\n",
    "\n",
    "Antes de transformar definitivamente nada, vamos a separar los datos en X e y. y será la columna objetivo, es decir, el precio. La columna objetivo nunca se toca, nunca se transforma en ningún sentido. X serán el resto de columnas, la características con las que realizaremos nuestras predicciones.\n",
    "\n",
    "**0 arreglar datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e873e-b811-4ad4-a7ba-e6a7d036a118",
   "metadata": {},
   "source": [
    "Antes de dividir nuestros datos vamos ver cuales de nuestras variables tienen una mayor correlación con nuestra variable dependiente, esto nos puede ayudar a la hora de elegir que variables escoger para entrenar a nuestro modelo, para ello utilizaremos la matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c450d-cb94-4e89-a828-7bea563216ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.set(style='white')\n",
    "\n",
    "mask=np.triu(np.ones_like(diamonts.corr(), dtype=bool))\n",
    "\n",
    "cmap=sns.diverging_palette(0, 10, as_cmap=True)\n",
    "\n",
    "\n",
    "sns.heatmap(diamonts.corr(),\n",
    "           mask=mask,\n",
    "          cmap=cmap,\n",
    "          center=0,\n",
    "          square=True,\n",
    "          annot=True,\n",
    "          linewidths=0.5,\n",
    "          cbar_kws={'shrink': 0.5});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22771c67-d52c-434f-b87f-f65ec1498b53",
   "metadata": {},
   "source": [
    "A simple vista podemos observar que 'depth','table' y 'density' tiene una correlacción muy baja con nuestra variable dependiente por lo que son candidatas a ser excluidas de nuestro set de entrenamiento, pero de momento vamos a dejarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09bb9e5-26ec-401c-8b9f-0fdfb435355d",
   "metadata": {},
   "source": [
    "El primer paso es separar los datos de entrenamiento de nuestro variable objetivo o variable dependiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df572aa7-1aa0-4a20-83ca-53c970571374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diamonts.drop('price', axis=1)\n",
    "\n",
    "y = diamonts.price\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aecafe-d842-4e5a-9257-7c4b844dab0a",
   "metadata": {},
   "source": [
    "Vamos a usar la transformación de box-cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc4efb-3f3b-4f18-85a8-e48c61785511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.carat=boxcox(X.carat, lmbda=2.618033)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9869812-c7cc-46a8-ac6e-f794af3b461b",
   "metadata": {},
   "source": [
    "Ahora volvemos a ejecutar la matriz de correlación pero en este caso buscamos ver la colinealidad de nuestras variables de entrenamiento entre ellas, ya que si tienen una correlación alta es un indicativo de colinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10dd76a-9d79-45d6-b3ff-338a55ddf575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.set(style='white')\n",
    "\n",
    "mask=np.triu(np.ones_like(X.corr(), dtype=bool))\n",
    "\n",
    "cmap=sns.diverging_palette(0, 10, as_cmap=True)\n",
    "\n",
    "\n",
    "sns.heatmap(X.corr(),\n",
    "           mask=mask,\n",
    "          cmap=cmap,\n",
    "          center=0,\n",
    "          square=True,\n",
    "          annot=True,\n",
    "          linewidths=0.5,\n",
    "          cbar_kws={'shrink': 0.5});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4144ad8-460f-49c7-ab82-047060853db2",
   "metadata": {},
   "source": [
    "Table tiene correlación negativa respecto a 'depth' y puede introducir ruido en nuestro modelo por lo que vamos a prescindir de ella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b529e-b62d-446c-a49b-7a26e3a504de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop('table', axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862532c-75ff-41bd-9e3d-fd8273ba36a5",
   "metadata": {},
   "source": [
    "Antes de continuar vemos que tenemos también columnas categóricas por lo que debemos de transformalas para que podamos incluirlas en nuestro análisis de correlación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b98978-7d1c-4dfd-9944-a11e82850251",
   "metadata": {},
   "source": [
    "**Tenemos diferentes métodos para transformar variables categóricas a númericas**\n",
    "    \n",
    "    + Generar variables dummies: Consiste en tomar cada uno de los valores únicos de nuestra columna y generar una columna nueva por cada uno de estos valores y transformalar a  binomial, es decir si la variable pertenece a ese valor o no, asignando 1 si lo es y 0 sino lo es.\n",
    "    + Label encoder: Básicamente es asignar un valor númerico a cada una de las categorías de nuestra columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91846496-cd3a-428b-88c9-5688e695dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dum=pd.get_dummies(X, columns=['cut', 'color', 'clarity'])   # drop_first=True, por defecto es False \n",
    "\n",
    "X_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811144ac-00d0-4bc9-90de-094b43c3d217",
   "metadata": {},
   "source": [
    "Hay que ser cauto con este tipo de transformación porque en el caso de que una de las columnas tenga un número elevado de categorías estaremos añadiendo muchas dimensiones a nuestros datos, con lo que aumentará su coste computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403b6c4-dabd-43a2-b54a-c02649710996",
   "metadata": {},
   "source": [
    "**Label Enconder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43268bb-7c9b-4f78-9730-e04b5ab5e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceffae6-10ed-4ec0-969d-a89041a0cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfaeec8-4b21-4418-b2fd-51b28a94bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Enc = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf385b-3e3a-44c1-b9da-1a3ea228103f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_Enc.cut = LabelEncoder().fit_transform(X_Enc.cut)\n",
    "X_Enc.color = LabelEncoder().fit_transform(X_Enc.color)\n",
    "X_Enc.clarity = LabelEncoder().fit_transform(X_Enc.clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e2f25-b671-425f-a32f-00ac40cff15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419f979-19e2-4bef-b5dc-4f94612f9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df.groupby('color').mean().index, \n",
    "            df.groupby('color').mean().price);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3939fc45-14bf-4d16-b354-cd666381be15",
   "metadata": {},
   "source": [
    "Cuidado con esto porque con esta transformación el modelo puede interpretar que cuando el color tiene una calificación de 'D' es menor, pero si investigamos un poco veremos que el 'D' es el rango más alto de color por lo que debería de ser al revés.\n",
    "\n",
    "[Color de los diamantes](https://www.tiffany.es/engagement/the-tiffany-guide-to-diamonds/color/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e7789-1b09-4bf4-bbfb-16a35c17bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder custom\n",
    "\n",
    "color={'J': 1, 'I': 2, 'H': 5, 'G':15, 'F': 25, 'E': 30, 'D':45}  # aqui es donde entra el conocimiento experto\n",
    "\n",
    "\n",
    "def cambio_color(x):   #esto es la lambda\n",
    "    return color[x]    # x es una key del diccionario color, color[x] es el value\n",
    "\n",
    "#X.color=X.color.apply(cambio_color)\n",
    "\n",
    "X.color=X.color.apply(lambda x: color[x])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ce56f-7b52-4ea1-bd0e-a04ab15d5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.cut = LabelEncoder().fit_transform(X.cut)\n",
    "X.clarity = LabelEncoder().fit_transform(X.clarity)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce3935-dd35-4afb-8f2f-31fdd5685927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.set(style='white')\n",
    "\n",
    "mask=np.triu(np.ones_like(X.corr(), dtype=bool))\n",
    "\n",
    "cmap=sns.diverging_palette(0, 10, as_cmap=True)\n",
    "\n",
    "\n",
    "sns.heatmap(X.corr(),\n",
    "           mask=mask,\n",
    "          cmap=cmap,\n",
    "          center=0,\n",
    "          square=True,\n",
    "          annot=True,\n",
    "          linewidths=0.5,\n",
    "          cbar_kws={'shrink': 0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad284c0-e1fd-4623-a299-f1a12d477d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['carat', 'cut', 'color', 'depth', 'density']]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf5f2f-afbe-485a-9fa0-6d56afa771ac",
   "metadata": {},
   "source": [
    "Una vez que nos hemos decantado por estas variables ahora sí vamos a dividir nuestro set de datos en entrenamiento y test, para ello utilizamemos el método train_test_split de la libería scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e4220-dfbb-46e4-9bee-3dd2c225bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # el alias es cosa mia\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=22)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b0a74-b1ea-4194-b7f8-5d0f8561d7ec",
   "metadata": {},
   "source": [
    "Si nos fijamos vemos que la escala de nuestros datos no es la misma en todas las columnas, en ocasiones y dependiendo del modelo esto no relevante, pero es bueno tenerlo en cuenta, por lo que sería bueno hacer varios experimentos para ver como es el desempeño de nuestro modelo.\n",
    "Existen varios modelos de escalado de datos, vamos a centrarnos en dos principalmente:\n",
    "\n",
    "    + Standar scaler: Esta transfomación realiza la siguiente operación "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43a0d0-6830-4304-8c5b-23b0799eb190",
   "metadata": {},
   "source": [
    "$$\\alpha =\\frac{ ({x}-\\mu)}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd195b2e-06ba-48fe-8a4f-da701576bdbb",
   "metadata": {},
   "source": [
    "    + Min - Max scaler:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d54862-319e-436e-9313-4c36b5c5fb75",
   "metadata": {},
   "source": [
    "$$\\alpha =\\frac{ ({x}-\\min)}{{\\max}-{\\min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d389efc-66a2-45c0-828f-dd59401f47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518127af-b29f-49c0-bf83-34090fe7837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(X_train)\n",
    "mm = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df905157-2838-4c6e-9193-2303dd15bd1b",
   "metadata": {},
   "source": [
    "Ahora con ellos podemos transformar nuestros set de datos y probarlos por separa para ver con cual de los dos funciona mejor, es importante realizar el ajuste del scaler únicamente con los datos train, con la intención de dar a nuestro modelo la menor información sobre los datos de test para que nuestro experimento sea lo más veraz posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf36589-ac17-40b9-bb2e-06bfb2e863ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = sc.transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "X_train_mm = mm.transform(X_train)\n",
    "X_test_mm = mm.transform(X_test)\n",
    "\n",
    "X_train_sc.shape, X_train_mm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7767b-3079-4f9f-8c40-f45e60878e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77fe6c-9992-43bc-90d5-d58a4b3524be",
   "metadata": {},
   "source": [
    "### 4. Elección de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e64ff8-b64e-4673-a2d0-b87ce6931fc2",
   "metadata": {},
   "source": [
    "Llegados a este punto y en base a la definición de nuestro objetivo tendremos que decantarnos por la elección de un modelo y sus hiperparámetros. Como hablamos al principio de este capítulo tenemos dos grandes grupos según la problemática que se nos plantee.\n",
    "\n",
    "    + Modelos de regresión. Para predecir un número (Caso que nos ocupa)\n",
    "    + Modelos de clasificación. Para predecir una clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd074-ee5c-4dc7-801a-e1aa4e5fc324",
   "metadata": {},
   "source": [
    "### 5. Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823cbc30-3227-483b-a446-25fc319c7b1b",
   "metadata": {},
   "source": [
    "Una vez que ya tenemos nuestros datos transfomados y escalados podemos proceder a entrenar nuestro modelo, para una primera aproximación vamos a decantarnos por el modelo más sencillo que es una regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4daa168-b4d6-4ecc-b3f5-b6cb8db26a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcf072-fa75-4e32-be57-59e2183a80a9",
   "metadata": {},
   "source": [
    "Vamos a generar tres modelos uno para cada uno de nuestros set de datos, uno para los que están sin estandarizar, otro para los datos de Standar Scaler y otro para los de Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd5cf7-2554-40e8-9a71-36997332d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LinearRegression()\n",
    "ln_sc = LinearRegression()\n",
    "ln_mm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34926d52-b67c-4a99-914d-a1992474848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.fit(X_train, y_train)\n",
    "ln_sc.fit(X_train_sc,y_train)\n",
    "ln_mm.fit(X_train_mm,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d45f7-d0b1-43bd-b31d-ed9674a5227c",
   "metadata": {},
   "source": [
    "### 6. Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41db90-14ac-4645-b2c6-694fb1b7fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds =ln.predict(X_test)\n",
    "preds_sc =ln_sc.predict(X_test_sc)\n",
    "preds_mm = ln_mm.predict(X_test_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc474e4-4e64-4980-82db-46121bb441b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce002568-4936-47da-8047-f3da3c6f160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a021676-f95c-4645-a16a-5b60e642aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mm[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3e563-0248-423e-af58-fb61f5871adf",
   "metadata": {},
   "source": [
    "### 7. Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1808895-0932-4388-8da2-863d34214b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.score(X_train, y_train), ln_sc.score(X_train_sc, y_train), ln_mm.score(X_train_mm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe530b-7175-4914-b664-ac28b272b1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ln.score(X_test, y_test), ln_sc.score(X_test_sc, y_test), ln_mm.score(X_test_mm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbfd30-d577-4eaf-b849-8e5f7a61fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25e68e-3ca9-4756-979b-c36b2378750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(y_train, ln.predict(X_train), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe579e-f41e-438e-97c8-f36b5ca783e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mse(y_test, preds, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e81012-b15e-4854-84b0-f33ccec311cb",
   "metadata": {},
   "source": [
    "### 8. Otros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c20e67-97dc-406d-8784-eaa3179d341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea546b5e-214b-4ec3-87b0-97d9cf78c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf_sc = RandomForestRegressor()\n",
    "rf_mm = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c9606-e5a1-4f4a-9ea7-99582ed39d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "rf_sc.fit(X_train_sc, y_train)\n",
    "rf_mm.fit(X_train_mm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc03f86-3592-4713-af3c-77191af20a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471bddd-5f02-4238-9795-29c8e7c6008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_train, y_train), rf_sc.score(X_train_sc, y_train), rf_mm.score(X_train_mm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1463a5d-a8e4-40f0-a897-3095380db1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test, y_test), rf_sc.score(X_test_sc, y_test), rf_mm.score(X_test_mm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60039b0a-a569-4711-b43e-603a1239e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(y_train, rf.predict(X_train), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af31b62-61c5-444a-9692-295837ead4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(y_test, rf.predict(X_test), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c60d93-104f-4004-a50a-335968e302b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
